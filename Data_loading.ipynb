{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPkSUQsXBB1l"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_ZDCo_bBAZK",
        "outputId": "ead7f73d-6c7d-4383-e103-1cc3baf6cdd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyreadstat\n",
            "  Downloading pyreadstat-1.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyreadstat) (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.16.0)\n",
            "Downloading pyreadstat-1.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyreadstat\n",
            "Successfully installed pyreadstat-1.2.7\n"
          ]
        }
      ],
      "source": [
        "!pip install pyreadstat\n",
        "# import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pyreadstat\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import glob\n",
        "import random\n",
        "import re\n",
        "import statsmodels.api as sm\n",
        "from pandas.api.types import CategoricalDtype\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import NeighborhoodComponentsAnalysis, KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "pd.options.display.max_columns = None\n",
        "pd.options.display.max_rows = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6AXAngFCSvg",
        "outputId": "ba0d7e03-75c4-4040-c2fa-c39fbc34d2fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['IDCNTRY', 'IDBOOK', 'IDSCHOOL', 'IDCLASS', 'IDSTUD', 'MP52024',\n",
            "       'MP52058A', 'MP52058B', 'MP52125', 'MP52229',\n",
            "       ...\n",
            "       'SE72140_S', 'SE72132_S', 'SE72209_S', 'SE72210_S', 'SE72249_S',\n",
            "       'SE72323_S', 'SE72368_S', 'SE72303_S', 'VERSION', 'SCOPE'],\n",
            "      dtype='object', length=2078)\n"
          ]
        }
      ],
      "source": [
        "# gather the metadata (column names) for the student assessment data\n",
        "meta = pyreadstat.read_sav('/content/drive/MyDrive/Data8/bsairnm7.sav', metadataonly=True)\n",
        "# select a subset of the columns for analysis\n",
        "stud_ach_cols = meta[0].columns\n",
        "print(stud_ach_cols)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(stud_ach_cols))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDE2MLbFxJop",
        "outputId": "3725c8c2-6d88-4f2c-a198-0525d794e5fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load"
      ],
      "metadata": {
        "id": "tBT2ClEbPMpg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "614uGlw_BOu4",
        "outputId": "80249ad6-f7f7-440a-bb14-77cb7250210b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Data8/bsrirnm7.sav\n",
            "/content/drive/MyDrive/Data8/bsgirnm7.sav\n",
            "/content/drive/MyDrive/Data8/bcgirnm7.sav\n",
            "/content/drive/MyDrive/Data8/bsairnm7.sav\n",
            "/content/drive/MyDrive/Data8/btmirnm7.sav\n",
            "/content/drive/MyDrive/Data8/bstirnm7.sav\n",
            "/content/drive/MyDrive/Data8/btsirnm7.sav\n"
          ]
        }
      ],
      "source": [
        "# initialize variables for reading in the TIMSS data\n",
        "school = 0\n",
        "stud_ach = 0\n",
        "student = 0\n",
        "stud_teach = 0\n",
        "math_teach = 0\n",
        "sci_teach = 0\n",
        "\n",
        "# loop through each SPSS file\n",
        "for file in glob.glob('/content/drive/MyDrive/Data8/*.sav'):\n",
        "    # print the file name to monitor progress\n",
        "    print(file)\n",
        "    # if file name contains \"bcg\" then it is a file with school level information\n",
        "    if re.search('bcg',file) != None:\n",
        "        # identify the subset of columns necessary for school level analysis\n",
        "        school_cols = ['IDCNTRY','IDSCHOOL','IDPOP','ITLANG_C','LCID_C','BCBGDAS','BCBGEAS','BCBGMRS','BCBGSRS','BCDGDAS','BCDGEAS',\n",
        "                       'BCDGMRS','BCDGSRS','BCDGSBC','BCDGTIHY']\n",
        "        school = pd.read_spss(file)\n",
        "    # if file name contains \"bsa\" then it is a file with student achievement level information\n",
        "    elif re.search('bsa',file) != None:\n",
        "\n",
        "        stud_ach = pd.read_spss(file)\n",
        "    # if file name contains \"bsg\" then it is a file with student level information\n",
        "    elif re.search('bsg',file) != None:\n",
        "\n",
        "        student = pd.read_spss(file)\n",
        "    # if file name contains \"bst\" then it is a file with student-teacher level information\n",
        "    elif re.search('bst',file) != None:\n",
        "        stud_teach = pd.read_spss(file)\n",
        "\n",
        "    # if file name contains \"btm\" then it is a file with math teacher level information\n",
        "    elif re.search('btm',file) != None:\n",
        "        math_teach = pd.read_spss(file)\n",
        "\n",
        "    # if file name contains \"bts\" then it is a file with science teacher level information\n",
        "    elif re.search('bts',file) != None:\n",
        "        sci_teach = pd.read_spss(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mabep-ORBoEI"
      },
      "outputs": [],
      "source": [
        "# column prefixes to drop from math teacher data\n",
        "math_teach_drop_cols = ['BTBM18','BTBM22','VERSION','SCOPE']\n",
        "# find all columns that contain the column prefixes\n",
        "for drop_head in math_teach_drop_cols:\n",
        "    drop_cols = [col for col in math_teach.columns if drop_head in col]\n",
        "# drop all matching columns\n",
        "math_teach.drop(columns=drop_cols,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTBSNjijBqHu"
      },
      "outputs": [],
      "source": [
        "# column prefixes to drop from science teacher data\n",
        "sci_teach_drop_cols = ['BTBS17','BTBS21','VERSION','SCOPE']\n",
        "# find all columns that contain the column prefixes\n",
        "for drop_head in sci_teach_drop_cols:\n",
        "    drop_cols = [col for col in sci_teach.columns if drop_head in col]\n",
        "# drop all matching columns\n",
        "sci_teach.drop(columns=drop_cols,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeamMFUVBsK4"
      },
      "outputs": [],
      "source": [
        "# identify the file containing all of the code interpretations\n",
        "file_name = '/content/drive/MyDrive/Codebooks/T19_G8_Codebook.xlsx'\n",
        "# store all codes into respectively named _codes dataframes\n",
        "school_codes = pd.read_excel(file_name, sheet_name='BCGM7').set_index('Variable').iloc[:,:1]\n",
        "stud_ach_codes = pd.read_excel(file_name, sheet_name='BSAM7').set_index('Variable').iloc[:,:1]\n",
        "student_codes = pd.read_excel(file_name, sheet_name='BSGM7').set_index('Variable').iloc[:,:1]\n",
        "stud_teach_codes = pd.read_excel(file_name, sheet_name='BSTM7').set_index('Variable').iloc[:,:1]\n",
        "math_teach_codes = pd.read_excel(file_name, sheet_name='BTMM7').set_index('Variable').iloc[:,:1]\n",
        "sci_teach_codes = pd.read_excel(file_name, sheet_name='BTSM7').set_index('Variable').iloc[:,:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qL6bKQ00BuH1"
      },
      "outputs": [],
      "source": [
        "def binary_scores(answer):\n",
        "    '''\n",
        "    converts each assessment item response into a binary number\n",
        "\n",
        "    INPUT:\n",
        "    answer - (str) the answer to the assessment item\n",
        "                CORRECT RESPONSE, INCORRECT RESPONSE or a multiple choice response (* denotes correct answer)\n",
        "\n",
        "    OUTPUT:\n",
        "    a binary score for where:\n",
        "            1 - correct response\n",
        "            0 - incorrect response\n",
        "    '''\n",
        "    # keep NaN responses as NaN\n",
        "    try:\n",
        "        float(answer)\n",
        "        return np.nan\n",
        "    except:\n",
        "        # if response is correct, return 1\n",
        "        if '*' in answer or ('CORRECT' in answer and 'INCORRECT' not in answer):\n",
        "            return 1\n",
        "        # otherwise, if the response is incorrect, return 0\n",
        "        elif '*' not in answer or ('INCORRECT' in answer):\n",
        "            return 0\n",
        "        # in any other situation, return NaN\n",
        "        else:\n",
        "            return np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YN8rYwiRBu5R"
      },
      "outputs": [],
      "source": [
        "def nanor(t):\n",
        "    '''\n",
        "    identifies if any correct answers are in the list\n",
        "\n",
        "    INPUT:\n",
        "    t - (list) an array of binary assessment responses\n",
        "\n",
        "    OUTPUT:\n",
        "    a binary score for where:\n",
        "            1 - correct response found\n",
        "            0 - no correct responses found\n",
        "            NaN - no responses found\n",
        "    '''\n",
        "    # remove nan responses from the list\n",
        "    t = list(filter(lambda x: str(x) != 'nan', t))\n",
        "    # if no valid responses found, return NaN\n",
        "    if len(t) == 0:\n",
        "        return np.nan\n",
        "    # otherwise, return 1 for any correct responses, 0 for no correct responses\n",
        "    else:\n",
        "        return int(any(t))\n",
        "\n",
        "def nanand(t):\n",
        "    '''\n",
        "    identifies if all answers in the list are correct\n",
        "\n",
        "    INPUT:\n",
        "    t - (list) an array of binary assessment responses\n",
        "\n",
        "    OUTPUT:\n",
        "    a binary score for where:\n",
        "            1 - all correct responses found\n",
        "            0 - not all correct responses found\n",
        "            NaN - no responses found\n",
        "    '''\n",
        "    # remove nan responses from the list\n",
        "    t = list(filter(lambda x: str(x) != 'nan', t))\n",
        "    # if no valid responses found, return NaN\n",
        "    if len(t) == 0:\n",
        "        return np.nan\n",
        "    # otherwise, return 1 for all correct responses, 0 for not all correct responses\n",
        "    else:\n",
        "        return int(all(t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Zx-Z3W_Byxf"
      },
      "outputs": [],
      "source": [
        "# combine results from paper and electronic assessments to avoid redundant and ambiguous assessment comparisons\n",
        "\n",
        "# create a list of all assessment columns from paper assessments (marked with a P) and that have not already been reduced to a single column\n",
        "paper_cols_all = [col1 for col1 in list(stud_ach.columns) if (col1[1] == 'P' and col1[-4:] != '_val')]\n",
        "\n",
        "# go through each columns\n",
        "for col1 in paper_cols_all:\n",
        "    # find all paper assessment columns that match the current column\n",
        "    paper_cols = [str(col2) for col2 in list(stud_ach.columns) if (col1[:7] in col2 and col2[-4:] != '_val')]\n",
        "    # find all electronic assessment columns that match the current column\n",
        "    elec_cols = [col3 for col3 in list(stud_ach.columns) if (col1[2:7] in col3 and col1[0] == col3[0] and col3[1] == 'E')]\n",
        "    # print the current columns being combined to monitor progress\n",
        "    print(col1, paper_cols + elec_cols)\n",
        "    # go through each of the matching paper or electronic assessment columns\n",
        "    for col in paper_cols+elec_cols:\n",
        "        # convert all answers to binary correct/incorrect values\n",
        "        stud_ach[col] = stud_ach[col].apply(binary_scores)\n",
        "    # if there are columns to be combined\n",
        "    if len(paper_cols) > 0:\n",
        "        # only count it as correct with all assessments were answered correctly (TIMSS assessment criteria)\n",
        "        # store the result in the first of the matching columns\n",
        "        stud_ach[paper_cols[0]] = stud_ach.loc[:,paper_cols].apply(nanand, axis=1)\n",
        "        stud_ach[elec_cols[0]] = stud_ach.loc[:,elec_cols].apply(nanand, axis=1)\n",
        "        # take the final results and combine the paper and electronic results into one column (marked with _val)\n",
        "        stud_ach[col1[:7]+'_val'] = stud_ach.loc[:,[paper_cols[0],elec_cols[0]]].apply(nanor, axis=1)\n",
        "        # drop previous paper and electronic assessment data to simplify the data set\n",
        "        stud_ach.drop(columns=paper_cols+elec_cols, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO5cRVg2B1Ux",
        "outputId": "c2ed4992-83db-4c54-ee48-9d3c674c2383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BSMMAT01', 'BSMMAT02', 'BSMMAT03', 'BSMMAT04', 'BSMMAT05']\n",
            "['BSSSCI01', 'BSSSCI02', 'BSSSCI03', 'BSSSCI04', 'BSSSCI05']\n",
            "['BSMALG01', 'BSMALG02', 'BSMALG03', 'BSMALG04', 'BSMALG05']\n",
            "['BSMAPP01', 'BSMAPP02', 'BSMAPP03', 'BSMAPP04', 'BSMAPP05']\n",
            "['BSMDAT01', 'BSMDAT02', 'BSMDAT03', 'BSMDAT04', 'BSMDAT05']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-0d4ca89581c3>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_avg'] = stud_ach.loc[:,sub_col].mean(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_sd'] = stud_ach.loc[:,sub_col].std(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_avg'] = stud_ach.loc[:,sub_col].mean(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_sd'] = stud_ach.loc[:,sub_col].std(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_avg'] = stud_ach.loc[:,sub_col].mean(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_sd'] = stud_ach.loc[:,sub_col].std(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_avg'] = stud_ach.loc[:,sub_col].mean(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_sd'] = stud_ach.loc[:,sub_col].std(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_avg'] = stud_ach.loc[:,sub_col].mean(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_sd'] = stud_ach.loc[:,sub_col].std(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_avg'] = stud_ach.loc[:,sub_col].mean(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_sd'] = stud_ach.loc[:,sub_col].std(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_avg'] = stud_ach.loc[:,sub_col].mean(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_sd'] = stud_ach.loc[:,sub_col].std(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_avg'] = stud_ach.loc[:,sub_col].mean(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_sd'] = stud_ach.loc[:,sub_col].std(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_avg'] = stud_ach.loc[:,sub_col].mean(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_sd'] = stud_ach.loc[:,sub_col].std(axis=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BSMGEO01', 'BSMGEO02', 'BSMGEO03', 'BSMGEO04', 'BSMGEO05']\n",
            "['BSMKNO01', 'BSMKNO02', 'BSMKNO03', 'BSMKNO04', 'BSMKNO05']\n",
            "['BSMNUM01', 'BSMNUM02', 'BSMNUM03', 'BSMNUM04', 'BSMNUM05']\n",
            "['BSMREA01', 'BSMREA02', 'BSMREA03', 'BSMREA04', 'BSMREA05']\n",
            "['BSSAPP01', 'BSSAPP02', 'BSSAPP03', 'BSSAPP04', 'BSSAPP05']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-0d4ca89581c3>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_avg'] = stud_ach.loc[:,sub_col].mean(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_sd'] = stud_ach.loc[:,sub_col].std(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_avg'] = stud_ach.loc[:,sub_col].mean(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_sd'] = stud_ach.loc[:,sub_col].std(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_avg'] = stud_ach.loc[:,sub_col].mean(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_sd'] = stud_ach.loc[:,sub_col].std(axis=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BSSBIO01', 'BSSBIO02', 'BSSBIO03', 'BSSBIO04', 'BSSBIO05']\n",
            "['BSSCHE01', 'BSSCHE02', 'BSSCHE03', 'BSSCHE04', 'BSSCHE05']\n",
            "['BSSEAR01', 'BSSEAR02', 'BSSEAR03', 'BSSEAR04', 'BSSEAR05']\n",
            "['BSSKNO01', 'BSSKNO02', 'BSSKNO03', 'BSSKNO04', 'BSSKNO05']\n",
            "['BSSPHY01', 'BSSPHY02', 'BSSPHY03', 'BSSPHY04', 'BSSPHY05']\n",
            "['BSSREA01', 'BSSREA02', 'BSSREA03', 'BSSREA04', 'BSSREA05']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-0d4ca89581c3>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_avg'] = stud_ach.loc[:,sub_col].mean(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_sd'] = stud_ach.loc[:,sub_col].std(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_avg'] = stud_ach.loc[:,sub_col].mean(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_sd'] = stud_ach.loc[:,sub_col].std(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_avg'] = stud_ach.loc[:,sub_col].mean(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_sd'] = stud_ach.loc[:,sub_col].std(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_avg'] = stud_ach.loc[:,sub_col].mean(axis=1)\n",
            "<ipython-input-13-0d4ca89581c3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  stud_ach[item.lower()+'_sd'] = stud_ach.loc[:,sub_col].std(axis=1)\n"
          ]
        }
      ],
      "source": [
        "# create a list of all math and science assessments\n",
        "scores = ['MMAT','SSCI','MALG','MAPP','MDAT','MGEO','MKNO','MNUM','MREA','SAPP','SBIO','SCHE','SEAR','SKNO','SPHY','SREA']\n",
        "\n",
        "# go through each math and science score category\n",
        "for item in scores:\n",
        "    # find all assessments of that category (TIMSS offers 5 estimate of each category per student)\n",
        "    sub_col = [col for col in stud_ach.columns if item in col]\n",
        "    # print the columns to show progress\n",
        "    print(sub_col)\n",
        "    # find the average assessment of the category from all estimates\n",
        "    stud_ach[item.lower()+'_avg'] = stud_ach.loc[:,sub_col].mean(axis=1)\n",
        "    stud_teach[item.lower()+'_avg'] = stud_teach.loc[:,sub_col].mean(axis=1)\n",
        "    # find the standard deviation of the estimates for that category\n",
        "    stud_ach[item.lower()+'_sd'] = stud_ach.loc[:,sub_col].std(axis=1)\n",
        "    # drop the previous five estimates to simplify to the average value\n",
        "    stud_ach.drop(sub_col, axis = 1, inplace=True)\n",
        "    stud_teach.drop(sub_col, axis = 1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vE4bXJQoB4RK"
      },
      "outputs": [],
      "source": [
        "# drop all weight and jackknife columns that are not relevant to the analysis\n",
        "stud_ach.drop(columns=[col for col in stud_ach.columns if 'WGT' in col or 'JK' in col], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1E3_lQ6SB6t-"
      },
      "outputs": [],
      "source": [
        "# store each dataframe into its own CSV file in the data folder\n",
        "school.to_csv('/content/drive/MyDrive/TIMSS/Iran2/school.csv', index = False)\n",
        "stud_ach.to_csv('/content/drive/MyDrive/TIMSS/Iran2/stud_ach.csv', index = False)\n",
        "student.to_csv('/content/drive/MyDrive/TIMSS/Iran2/student.csv', index = False)\n",
        "stud_teach.to_csv('/content/drive/MyDrive/TIMSS/Iran2/stud_teach.csv', index = False)\n",
        "math_teach.to_csv('/content/drive/MyDrive/TIMSS/Iran2/math_teach.csv', index = False)\n",
        "sci_teach.to_csv('/content/drive/MyDrive/TIMSS/Iran2/sci_teach.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GcozKyibKjWw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}